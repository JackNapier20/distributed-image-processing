version: "3.9"

networks:
  hadoop-net:
    driver: bridge

volumes:
  datanode-data:
  local-images:

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    hostname: namenode
    environment:
      - CLUSTER_NAME=endsem
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    ports:
      - "9000:9000"
      - "50070:50070"
    networks: [ hadoop-net ]

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    depends_on: [ namenode ]
    environment:
      - CLUSTER_NAME=endsem
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    volumes:
      - datanode-data:/hadoop/dfs/data
    ports:
      - "50075:50075"
    networks: [ hadoop-net ]

  spark-master:
    build: ./app
    hostname: spark-master
    environment:
      - SPARK_MODE=master
      - PYSPARK_PYTHON=/usr/bin/python3
    command: [ "/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master", "--host", "spark-master", "--port", "7077", "--webui-port", "8080" ]
    ports:
      - "7077:7077"
      - "8080:8080"
    networks: [ hadoop-net ]

  spark-worker:
    build: ./app
    depends_on: [ spark-master ]
    environment:
      - SPARK_MODE=worker
      - PYSPARK_PYTHON=/usr/bin/python3
      - SPARK_WORKER_MEMORY=12g
      - SPARK_WORKER_CORES=4

    command: [ "/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077" ]
    expose:
      - "8081"
    networks: [ hadoop-net ]

  image-app:
    build: ./app
    hostname: image-app
    container_name: image-app
    depends_on:
      - spark-master
      - spark-worker
      - namenode
      - datanode
    environment:
      - HADOOP_CONF_DIR=/etc/hadoop
    volumes:
      - ./hadoop-config:/etc/hadoop
      - ./app:/app
      - ./images:/local_images
    ports:
      - "7079:7079"
    command: sleep infinity
    networks:
      - hadoop-net
